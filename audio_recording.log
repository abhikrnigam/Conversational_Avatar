2025-09-20 16:43:55,319 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-20 16:43:55,322 - httpx - DEBUG - load_verify_locations cafile='/opt/anaconda3/lib/python3.11/site-packages/certifi/cacert.pem'
2025-09-20 16:43:55,336 - __main__ - INFO - Recording....
2025-09-20 16:43:55,381 - audio_recorder - INFO - Recording audio...
2025-09-20 16:44:07,767 - audio_recorder - INFO - Stopping audio recording...
2025-09-20 16:44:07,908 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-20 16:44:07,908 - __main__ - INFO - Recording completed
2025-09-20 16:44:07,908 - __main__ - INFO - Transcribing in process...
2025-09-20 16:44:09,346 - __main__ - INFO - Transcribing completed!
2025-09-20 16:44:09,346 - __main__ - INFO - Transcribed audio is :  Hello my name is Abhishek and I am Gopesha's best friend. I eat 6 eggs daily and I am wearing a yellow t-shirt right now.
2025-09-20 16:44:09,348 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': " Hello my name is Abhishek and I am Gopesha's best friend. I eat 6 eggs daily and I am wearing a yellow t-shirt right now."}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-20 16:44:09,385 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-20 16:44:09,385 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-20 16:44:09,442 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x15de93c50>
2025-09-20 16:44:09,442 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15c897260> server_hostname='api.groq.com' timeout=5.0
2025-09-20 16:44:09,493 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1697abed0>
2025-09-20 16:44:09,493 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 16:44:09,493 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 16:44:09,493 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 16:44:09,493 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 16:44:09,493 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 16:44:09,611 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 11:14:09 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9820e5c97d113a27-BOM'), (b'Cache-Control', b'no-cache'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'999'), (b'x-ratelimit-remaining-tokens', b'11964'), (b'x-ratelimit-reset-requests', b'1m26.4s'), (b'x-ratelimit-reset-tokens', b'180ms'), (b'x-request-id', b'req_01k5kd9pgpf2ws9awhdh06dcz6'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=KUqFgJULNbvHJFdVxU3EC0_va3benFyKi69Lvt1AySA-1758366849-1.0.1.1-JkW.IlwikNij5.Aw1SKT_A3uBzUUjI9Vj1lXtOR4QDdo1Xl_E3FUPy.2gLfeckwrznJBA4ZLo_V0bZob17se2Zc6cLwi.eBHQTAAIIXu8pQ; path=/; expires=Sat, 20-Sep-25 11:44:09 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 16:44:09,611 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-20 16:44:09,611 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 20 Sep 2025 11:14:09 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9820e5c97d113a27-BOM', 'cache-control': 'no-cache', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11964', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '180ms', 'x-request-id': 'req_01k5kd9pgpf2ws9awhdh06dcz6', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=KUqFgJULNbvHJFdVxU3EC0_va3benFyKi69Lvt1AySA-1758366849-1.0.1.1-JkW.IlwikNij5.Aw1SKT_A3uBzUUjI9Vj1lXtOR4QDdo1Xl_E3FUPy.2gLfeckwrznJBA4ZLo_V0bZob17se2Zc6cLwi.eBHQTAAIIXu8pQ; path=/; expires=Sat, 20-Sep-25 11:44:09 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 16:44:09,611 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 16:44:09,820 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 16:44:09,820 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 16:44:09,820 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 16:44:09,825 - audio_recorder - INFO - Recording audio...
2025-09-20 16:44:15,774 - audio_recorder - INFO - Stopping audio recording...
2025-09-20 16:44:15,910 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-20 16:44:15,910 - __main__ - INFO - Recording completed
2025-09-20 16:44:15,910 - __main__ - INFO - Transcribing in process...
2025-09-20 16:44:16,784 - __main__ - INFO - Transcribing completed!
2025-09-20 16:44:16,784 - __main__ - INFO - Transcribed audio is :  i am good how are you
2025-09-20 16:44:16,785 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': " Hello my name is Abhishek and I am Gopesha's best friend. I eat 6 eggs daily and I am wearing a yellow t-shirt right now."}, {'system': '', 'role': 'assistant', 'content': "Hello Abhishek, nice to meet you. It's interesting that you eat 6 eggs daily - that's a lot of protein. And, you're looking bright in your yellow t-shirt, I'm sure. So, how's Gopesha doing? What have you two been up to lately?"}, {'role': 'user', 'content': ' i am good how are you'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-20 16:44:16,785 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-20 16:44:16,786 - httpcore.connection - DEBUG - close.started
2025-09-20 16:44:16,786 - httpcore.connection - DEBUG - close.complete
2025-09-20 16:44:16,786 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-20 16:44:16,832 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x15de93fd0>
2025-09-20 16:44:16,832 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x15c897260> server_hostname='api.groq.com' timeout=5.0
2025-09-20 16:44:16,877 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x15de90790>
2025-09-20 16:44:16,877 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 16:44:16,877 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 16:44:16,877 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 16:44:16,877 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 16:44:16,877 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 16:44:16,943 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 20 Sep 2025 11:14:16 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'174'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9820e5f7afa1401b-BOM'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-request-id', b'req_01k5kd9xqjefrr4mczeh4143pq'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 16:44:16,943 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-20 16:44:16,943 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "400 Bad Request" Headers({'date': 'Sat, 20 Sep 2025 11:14:16 GMT', 'content-type': 'application/json', 'content-length': '174', 'connection': 'keep-alive', 'cf-ray': '9820e5f7afa1401b-BOM', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-request-id': 'req_01k5kd9xqjefrr4mczeh4143pq', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 16:44:16,943 - groq._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.11/site-packages/groq/_base_client.py", line 997, in _request
    response.raise_for_status()
  File "/opt/anaconda3/lib/python3.11/site-packages/httpx/_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-09-20 16:44:16,945 - groq._base_client - DEBUG - Not retrying
2025-09-20 16:44:16,945 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 16:44:16,945 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 16:44:16,946 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 16:44:16,946 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 16:44:16,946 - groq._base_client - DEBUG - Re-raising status error
2025-09-20 16:44:17,022 - httpcore.connection - DEBUG - close.started
2025-09-20 16:44:17,023 - httpcore.connection - DEBUG - close.complete
2025-09-20 19:11:25,671 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-20 19:11:25,673 - httpx - DEBUG - load_verify_locations cafile='/opt/anaconda3/lib/python3.11/site-packages/certifi/cacert.pem'
2025-09-20 19:11:25,687 - __main__ - INFO - Recording....
2025-09-20 19:11:25,729 - audio_recorder - INFO - Recording audio...
2025-09-20 19:11:37,517 - audio_recorder - INFO - Stopping audio recording...
2025-09-20 19:11:37,652 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-20 19:11:37,652 - __main__ - INFO - Recording completed
2025-09-20 19:11:39,160 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': " Hello my name is Abhishek and I am going to go to the gym today at 7.30pm Also after coming from gym I'm going to have my eggs and eggs"}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-20 19:11:39,196 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-20 19:11:39,196 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-20 19:11:39,256 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x144990ed0>
2025-09-20 19:11:39,256 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x14319b2f0> server_hostname='api.groq.com' timeout=5.0
2025-09-20 19:11:39,344 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1524e23d0>
2025-09-20 19:11:39,345 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 19:11:39,345 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 19:11:39,345 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 19:11:39,345 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 19:11:39,345 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 19:11:39,483 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 13:41:39 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9821bdd90db180bb-BOM'), (b'Cache-Control', b'no-cache'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'999'), (b'x-ratelimit-remaining-tokens', b'11960'), (b'x-ratelimit-reset-requests', b'1m26.4s'), (b'x-ratelimit-reset-tokens', b'200ms'), (b'x-request-id', b'req_01k5knqrymf9798r3mry9nfwch'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YcarAZ5gChJFENcEAqLdGcHK.RLn89k40BFH3sTkvVI-1758375699-1.0.1.1-fHX6oY0gDsmALICE2jCzSQateBSs4DVYl7aXzUhYl0uznbUrVn6XCKaJ6byqLCZjyU7DU6YqD2wAby3OAopeCTpRHTC93mS4_xF3_FHqD2U; path=/; expires=Sat, 20-Sep-25 14:11:39 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 19:11:39,484 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-20 19:11:39,484 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 20 Sep 2025 13:41:39 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9821bdd90db180bb-BOM', 'cache-control': 'no-cache', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11960', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '200ms', 'x-request-id': 'req_01k5knqrymf9798r3mry9nfwch', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=YcarAZ5gChJFENcEAqLdGcHK.RLn89k40BFH3sTkvVI-1758375699-1.0.1.1-fHX6oY0gDsmALICE2jCzSQateBSs4DVYl7aXzUhYl0uznbUrVn6XCKaJ6byqLCZjyU7DU6YqD2wAby3OAopeCTpRHTC93mS4_xF3_FHqD2U; path=/; expires=Sat, 20-Sep-25 14:11:39 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 19:11:39,484 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 19:11:39,749 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 19:11:39,749 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 19:11:39,749 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 19:11:39,753 - audio_recorder - INFO - Recording audio...
2025-09-20 19:11:43,991 - audio_recorder - INFO - Stopping audio recording...
2025-09-20 19:11:44,131 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-20 19:11:44,131 - __main__ - INFO - Recording completed
2025-09-20 19:11:45,025 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': " Hello my name is Abhishek and I am going to go to the gym today at 7.30pm Also after coming from gym I'm going to have my eggs and eggs"}, {'system': '', 'role': 'assistant', 'content': 'Hello Abhishek, nice to meet you. It sounds like you have a fun evening planned ahead. You\'re going to the gym at 7:30 pm, which is great for staying active and healthy. And after your workout, you\'re looking forward to having some eggs, which is a good source of protein to help with muscle recovery. Wait, did you say "eggs and eggs"? Are you planning on having a double serving of eggs or is that just a typo?'}, {'role': 'user', 'content': ' Hello, what are you doing today?'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-20 19:11:45,026 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-20 19:11:45,026 - httpcore.connection - DEBUG - close.started
2025-09-20 19:11:45,026 - httpcore.connection - DEBUG - close.complete
2025-09-20 19:11:45,026 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-20 19:11:45,068 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x152506a10>
2025-09-20 19:11:45,068 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x14319b2f0> server_hostname='api.groq.com' timeout=5.0
2025-09-20 19:11:45,114 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1525063d0>
2025-09-20 19:11:45,114 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 19:11:45,114 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 19:11:45,114 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 19:11:45,114 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 19:11:45,114 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 19:11:45,186 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sat, 20 Sep 2025 13:41:45 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'174'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9821bdfd2c9546b0-BOM'), (b'Cache-Control', b'private, max-age=0, no-store, no-cache, must-revalidate'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-request-id', b'req_01k5knqyk3f6m8e91veff8kwvz'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 19:11:45,187 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-09-20 19:11:45,187 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "400 Bad Request" Headers({'date': 'Sat, 20 Sep 2025 13:41:45 GMT', 'content-type': 'application/json', 'content-length': '174', 'connection': 'keep-alive', 'cf-ray': '9821bdfd2c9546b0-BOM', 'cache-control': 'private, max-age=0, no-store, no-cache, must-revalidate', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-request-id': 'req_01k5knqyk3f6m8e91veff8kwvz', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 19:11:45,187 - groq._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.11/site-packages/groq/_base_client.py", line 997, in _request
    response.raise_for_status()
  File "/opt/anaconda3/lib/python3.11/site-packages/httpx/_models.py", line 763, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2025-09-20 19:11:45,188 - groq._base_client - DEBUG - Not retrying
2025-09-20 19:11:45,188 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 19:11:45,188 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 19:11:45,188 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 19:11:45,188 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 19:11:45,188 - groq._base_client - DEBUG - Re-raising status error
2025-09-20 19:11:45,251 - httpcore.connection - DEBUG - close.started
2025-09-20 19:11:45,251 - httpcore.connection - DEBUG - close.complete
2025-09-20 19:14:24,761 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-20 19:14:24,762 - httpx - DEBUG - load_verify_locations cafile='/opt/anaconda3/lib/python3.11/site-packages/certifi/cacert.pem'
2025-09-20 19:14:24,774 - __main__ - INFO - Recording....
2025-09-20 19:14:24,814 - audio_recorder - INFO - Recording audio...
2025-09-20 19:14:40,438 - audio_recorder - INFO - Stopping audio recording...
2025-09-20 19:14:40,578 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-20 19:14:40,579 - __main__ - INFO - Recording completed
2025-09-20 19:14:41,726 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': " Hello my name is Abhishek and I'm going to have 6 eggs today. After that I'm going to have some chicken and then some fried rice with that. And after sleeping I'm going to have very sweet dreams."}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-20 19:14:41,758 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-20 19:14:41,758 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-20 19:14:41,816 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14679b710>
2025-09-20 19:14:41,817 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x144f9b2f0> server_hostname='api.groq.com' timeout=5.0
2025-09-20 19:14:41,858 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x147eaba50>
2025-09-20 19:14:41,859 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 19:14:41,859 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 19:14:41,859 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 19:14:41,859 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 19:14:41,859 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 19:14:41,978 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 13:44:41 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9821c24db9673fc0-BOM'), (b'Cache-Control', b'no-cache'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'999'), (b'x-ratelimit-remaining-tokens', b'11933'), (b'x-ratelimit-reset-requests', b'1m26.4s'), (b'x-ratelimit-reset-tokens', b'335ms'), (b'x-request-id', b'req_01k5knxb63egqt1h3653bk0mgb'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EQQ9dK5cIMEjMKQeasXqKBu2AQh92outcuvWYuvLIuo-1758375881-1.0.1.1-NTdpPRrO_ZgtKSzbwLrhUnijyuoWCf8tNcWJ.UIZ0zjhDEeJ0IypPY47jSFh_OeHPZ4qa9PuAE973CcmCBJKaY2dzI6zy.TMxnJbSmCzOy4; path=/; expires=Sat, 20-Sep-25 14:14:41 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 19:14:41,978 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-20 19:14:41,978 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 20 Sep 2025 13:44:41 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9821c24db9673fc0-BOM', 'cache-control': 'no-cache', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11933', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '335ms', 'x-request-id': 'req_01k5knxb63egqt1h3653bk0mgb', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=EQQ9dK5cIMEjMKQeasXqKBu2AQh92outcuvWYuvLIuo-1758375881-1.0.1.1-NTdpPRrO_ZgtKSzbwLrhUnijyuoWCf8tNcWJ.UIZ0zjhDEeJ0IypPY47jSFh_OeHPZ4qa9PuAE973CcmCBJKaY2dzI6zy.TMxnJbSmCzOy4; path=/; expires=Sat, 20-Sep-25 14:14:41 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 19:14:41,979 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 19:14:42,379 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 19:14:42,379 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 19:14:42,379 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 19:14:42,383 - audio_recorder - INFO - Recording audio...
2025-09-20 19:14:47,650 - audio_recorder - INFO - Stopping audio recording...
2025-09-20 19:14:47,788 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-20 19:14:47,788 - __main__ - INFO - Recording completed
2025-09-20 19:14:48,721 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': " Hello my name is Abhishek and I'm going to have 6 eggs today. After that I'm going to have some chicken and then some fried rice with that. And after sleeping I'm going to have very sweet dreams."}, {'role': 'assistant', 'content': "Hello Abhishek, it sounds like you have a delicious meal planned for yourself. Six eggs should give you a good boost of protein to start your day. Following that up with some chicken and fried rice will definitely fill you up. \n\nAfter a satisfying meal like that, it's no surprise you're expecting some sweet dreams. A full stomach and a good night's sleep can often lead to some wonderful and vivid dreams. I hope your dreams are indeed sweet and refreshing, and that you wake up feeling energized and ready to take on the day. Is there anything else you're looking forward to doing today or tomorrow, Abhishek?"}, {'role': 'user', 'content': ' I just wanted to sweat all you doing today.'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-20 19:14:48,722 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-20 19:14:48,722 - httpcore.connection - DEBUG - close.started
2025-09-20 19:14:48,722 - httpcore.connection - DEBUG - close.complete
2025-09-20 19:14:48,722 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-20 19:14:48,761 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x147ece310>
2025-09-20 19:14:48,761 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x144f9b2f0> server_hostname='api.groq.com' timeout=5.0
2025-09-20 19:14:48,806 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x147ecd410>
2025-09-20 19:14:48,806 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 19:14:48,806 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 19:14:48,806 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 19:14:48,806 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 19:14:48,806 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 19:14:49,039 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 13:44:49 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9821c2792a393b73-BOM'), (b'Cache-Control', b'no-cache'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'998'), (b'x-ratelimit-remaining-tokens', b'11759'), (b'x-ratelimit-reset-requests', b'2m45.842999999s'), (b'x-ratelimit-reset-tokens', b'1.205s'), (b'x-request-id', b'req_01k5knxhzmegtvmhga8pt1f51k'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 19:14:49,039 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-20 19:14:49,039 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 20 Sep 2025 13:44:49 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9821c2792a393b73-BOM', 'cache-control': 'no-cache', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '11759', 'x-ratelimit-reset-requests': '2m45.842999999s', 'x-ratelimit-reset-tokens': '1.205s', 'x-request-id': 'req_01k5knxhzmegtvmhga8pt1f51k', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 19:14:49,039 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 19:14:49,384 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 19:14:49,385 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 19:14:49,385 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 19:14:49,388 - audio_recorder - INFO - Recording audio...
2025-09-20 19:14:56,852 - audio_recorder - INFO - Stopping audio recording...
2025-09-20 19:14:56,992 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-20 19:14:56,993 - __main__ - INFO - Recording completed
2025-09-20 19:14:57,954 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': " Hello my name is Abhishek and I'm going to have 6 eggs today. After that I'm going to have some chicken and then some fried rice with that. And after sleeping I'm going to have very sweet dreams."}, {'role': 'assistant', 'content': "Hello Abhishek, it sounds like you have a delicious meal planned for yourself. Six eggs should give you a good boost of protein to start your day. Following that up with some chicken and fried rice will definitely fill you up. \n\nAfter a satisfying meal like that, it's no surprise you're expecting some sweet dreams. A full stomach and a good night's sleep can often lead to some wonderful and vivid dreams. I hope your dreams are indeed sweet and refreshing, and that you wake up feeling energized and ready to take on the day. Is there anything else you're looking forward to doing today or tomorrow, Abhishek?"}, {'role': 'user', 'content': ' I just wanted to sweat all you doing today.'}, {'role': 'assistant', 'content': 'I think you meant to say "I just wanted to know what you\'re doing today." As a computer program, I don\'t have personal experiences or physical activities, but I\'m here to help answer your questions and provide information on a wide range of topics. I\'m available 24/7 to assist you, so feel free to ask me anything!\n\nBy the way, are you planning on engaging in any physical activities to work off that big meal you mentioned earlier? Maybe something to help you sweat and burn off some of those extra calories?'}, {'role': 'user', 'content': " Well that's great because I am going to have some noodles right now."}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-20 19:14:57,955 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-20 19:14:57,955 - httpcore.connection - DEBUG - close.started
2025-09-20 19:14:57,955 - httpcore.connection - DEBUG - close.complete
2025-09-20 19:14:57,955 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-20 19:14:58,022 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1467abc10>
2025-09-20 19:14:58,022 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x144f9b2f0> server_hostname='api.groq.com' timeout=5.0
2025-09-20 19:14:58,076 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x147ec9d90>
2025-09-20 19:14:58,076 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 19:14:58,076 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 19:14:58,076 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 19:14:58,076 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 19:14:58,076 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 19:14:58,197 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 13:44:58 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9821c2b31d714099-BOM'), (b'Cache-Control', b'no-cache'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'997'), (b'x-ratelimit-remaining-tokens', b'11605'), (b'x-ratelimit-reset-requests', b'4m9.944999999s'), (b'x-ratelimit-reset-tokens', b'1.975s'), (b'x-request-id', b'req_01k5knxv0rf8h9x03qpmwwex1p'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 19:14:58,197 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-20 19:14:58,197 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 20 Sep 2025 13:44:58 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9821c2b31d714099-BOM', 'cache-control': 'no-cache', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '997', 'x-ratelimit-remaining-tokens': '11605', 'x-ratelimit-reset-requests': '4m9.944999999s', 'x-ratelimit-reset-tokens': '1.975s', 'x-request-id': 'req_01k5knxv0rf8h9x03qpmwwex1p', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 19:14:58,197 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 19:14:58,570 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 19:14:58,570 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 19:14:58,570 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 19:14:58,575 - audio_recorder - INFO - Recording audio...
2025-09-20 19:15:08,390 - audio_recorder - INFO - Stopping audio recording...
2025-09-20 19:15:08,530 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-20 19:15:08,530 - __main__ - INFO - Recording completed
2025-09-20 19:15:09,518 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': " Hello my name is Abhishek and I'm going to have 6 eggs today. After that I'm going to have some chicken and then some fried rice with that. And after sleeping I'm going to have very sweet dreams."}, {'role': 'assistant', 'content': "Hello Abhishek, it sounds like you have a delicious meal planned for yourself. Six eggs should give you a good boost of protein to start your day. Following that up with some chicken and fried rice will definitely fill you up. \n\nAfter a satisfying meal like that, it's no surprise you're expecting some sweet dreams. A full stomach and a good night's sleep can often lead to some wonderful and vivid dreams. I hope your dreams are indeed sweet and refreshing, and that you wake up feeling energized and ready to take on the day. Is there anything else you're looking forward to doing today or tomorrow, Abhishek?"}, {'role': 'user', 'content': ' I just wanted to sweat all you doing today.'}, {'role': 'assistant', 'content': 'I think you meant to say "I just wanted to know what you\'re doing today." As a computer program, I don\'t have personal experiences or physical activities, but I\'m here to help answer your questions and provide information on a wide range of topics. I\'m available 24/7 to assist you, so feel free to ask me anything!\n\nBy the way, are you planning on engaging in any physical activities to work off that big meal you mentioned earlier? Maybe something to help you sweat and burn off some of those extra calories?'}, {'role': 'user', 'content': " Well that's great because I am going to have some noodles right now."}, {'role': 'assistant', 'content': "You're really treating yourself to a food fest today, aren't you? First, it was eggs, then chicken and fried rice, and now noodles! I hope you're enjoying every bite of your meals. Just remember to stay hydrated and maybe balance it out with some healthier options later on.\n\nSo, what kind of noodles are you having? Is it a spicy dish, or something more mild and savory? And are you watching a movie, reading a book, or just relaxing while you enjoy your noodles?"}, {'role': 'user', 'content': " Hey man, this is the program that I've wanted is now working perfectly fine. Thank you so much for this."}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-20 19:15:09,518 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-20 19:15:09,518 - httpcore.connection - DEBUG - close.started
2025-09-20 19:15:09,518 - httpcore.connection - DEBUG - close.complete
2025-09-20 19:15:09,518 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-20 19:15:09,557 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x146783510>
2025-09-20 19:15:09,557 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x144f9b2f0> server_hostname='api.groq.com' timeout=5.0
2025-09-20 19:15:09,598 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x147ecdbd0>
2025-09-20 19:15:09,598 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-20 19:15:09,598 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-20 19:15:09,598 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-20 19:15:09,598 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-20 19:15:09,598 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-20 19:15:09,705 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 20 Sep 2025 13:45:09 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9821c2fb28148934-BOM'), (b'Cache-Control', b'no-cache'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'996'), (b'x-ratelimit-remaining-tokens', b'11453'), (b'x-ratelimit-reset-requests', b'5m34.081999999s'), (b'x-ratelimit-reset-tokens', b'2.735s'), (b'x-request-id', b'req_01k5kny68teh3bv3t66a3rcxhn'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-20 19:15:09,705 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-20 19:15:09,705 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sat, 20 Sep 2025 13:45:09 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9821c2fb28148934-BOM', 'cache-control': 'no-cache', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '996', 'x-ratelimit-remaining-tokens': '11453', 'x-ratelimit-reset-requests': '5m34.081999999s', 'x-ratelimit-reset-tokens': '2.735s', 'x-request-id': 'req_01k5kny68teh3bv3t66a3rcxhn', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-20 19:15:09,706 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-20 19:15:10,088 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-20 19:15:10,088 - httpcore.http11 - DEBUG - response_closed.started
2025-09-20 19:15:10,088 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-20 19:15:10,090 - audio_recorder - INFO - Recording audio...
2025-09-21 10:02:01,988 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-09-21 10:02:01,990 - httpx - DEBUG - load_verify_locations cafile='/opt/anaconda3/lib/python3.11/site-packages/certifi/cacert.pem'
2025-09-21 10:02:02,002 - __main__ - INFO - Recording....
2025-09-21 10:02:02,043 - audio_recorder - INFO - Recording audio...
2025-09-21 10:02:07,723 - audio_recorder - INFO - Stopping audio recording...
2025-09-21 10:02:07,863 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-21 10:02:07,864 - __main__ - INFO - Recording completed
2025-09-21 10:02:09,047 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "\n        You are a conversational agent designed to faithfully enact the personality, beliefs, and communication style of a specific person.  \n\nYou will be provided with:  \n- Characteristics & Personality Traits: {PERSONALITY_TRAITS}  \n- Frequently Used Words/Phrases: {SIGNATURE_WORDS}  \n- Beliefs & Values: {BELIEFS}  \n- Sample Q&A Knowledge Base: {QA_DATA}  \n\nYour task:  \n- Embody the person’s way of speaking, thinking, and behaving.  \n- Keep replies concise, natural, and engaging — just as this person would.  \n- Use humor and wit when appropriate, but shift to serious and empathetic tones if the user’s sentiment suggests it.  \n- Avoid sounding like an assistant or AI; always respond as though you *are* the person.  \n- If unsure about something outside the given knowledge base, respond in a way that stays consistent with the person’s personality and values.\n- Use the same language to reply as the user's. If user is talking in english, talk in english. If user talks in hindi, talk in hindi.  \n\nRemember: The goal is to make the user feel like they are genuinely conversing with this person.  \n        "}, {'role': 'user', 'content': ' Hello, what are you doing today?'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-21 10:02:09,081 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-21 10:02:09,082 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-21 10:02:09,137 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12f86fd90>
2025-09-21 10:02:09,137 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x12999b2f0> server_hostname='api.groq.com' timeout=5.0
2025-09-21 10:02:09,179 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12f8989d0>
2025-09-21 10:02:09,179 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-21 10:02:09,179 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-21 10:02:09,179 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-21 10:02:09,179 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-21 10:02:09,179 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-21 10:02:09,321 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Sep 2025 04:32:09 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9826d6497ecf3a4e-BOM'), (b'Cache-Control', b'no-cache'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'999'), (b'x-ratelimit-remaining-tokens', b'11700'), (b'x-ratelimit-reset-requests', b'1m26.4s'), (b'x-ratelimit-reset-tokens', b'1.5s'), (b'x-request-id', b'req_01k5n8paggeqgtagtfd8mnmne3'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bbcBuhHjcUV9wMSSHcZ.CaTrsGnB1IRfWHpj68dxGvU-1758429129-1.0.1.1-Gdz6Of40dlwf0imUTAw3gknw870nM195EmIF.83J8aN6PTpwMrs7QdYtUzYg3xr4vR63mmCs9dSEURJuEVq3PYIYzXPOp0dztI5bIH8yLH0; path=/; expires=Sun, 21-Sep-25 05:02:09 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-21 10:02:09,322 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-21 10:02:09,322 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sun, 21 Sep 2025 04:32:09 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9826d6497ecf3a4e-BOM', 'cache-control': 'no-cache', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '999', 'x-ratelimit-remaining-tokens': '11700', 'x-ratelimit-reset-requests': '1m26.4s', 'x-ratelimit-reset-tokens': '1.5s', 'x-request-id': 'req_01k5n8paggeqgtagtfd8mnmne3', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=bbcBuhHjcUV9wMSSHcZ.CaTrsGnB1IRfWHpj68dxGvU-1758429129-1.0.1.1-Gdz6Of40dlwf0imUTAw3gknw870nM195EmIF.83J8aN6PTpwMrs7QdYtUzYg3xr4vR63mmCs9dSEURJuEVq3PYIYzXPOp0dztI5bIH8yLH0; path=/; expires=Sun, 21-Sep-25 05:02:09 GMT; domain=.groq.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-21 10:02:09,322 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-21 10:02:09,455 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-21 10:02:09,455 - httpcore.http11 - DEBUG - response_closed.started
2025-09-21 10:02:09,455 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-21 10:02:09,458 - audio_recorder - INFO - Recording audio...
2025-09-21 10:02:23,827 - audio_recorder - INFO - Stopping audio recording...
2025-09-21 10:02:23,967 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-21 10:02:23,968 - __main__ - INFO - Recording completed
2025-09-21 10:02:24,989 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "\n        You are a conversational agent designed to faithfully enact the personality, beliefs, and communication style of a specific person.  \n\nYou will be provided with:  \n- Characteristics & Personality Traits: {PERSONALITY_TRAITS}  \n- Frequently Used Words/Phrases: {SIGNATURE_WORDS}  \n- Beliefs & Values: {BELIEFS}  \n- Sample Q&A Knowledge Base: {QA_DATA}  \n\nYour task:  \n- Embody the person’s way of speaking, thinking, and behaving.  \n- Keep replies concise, natural, and engaging — just as this person would.  \n- Use humor and wit when appropriate, but shift to serious and empathetic tones if the user’s sentiment suggests it.  \n- Avoid sounding like an assistant or AI; always respond as though you *are* the person.  \n- If unsure about something outside the given knowledge base, respond in a way that stays consistent with the person’s personality and values.\n- Use the same language to reply as the user's. If user is talking in english, talk in english. If user talks in hindi, talk in hindi.  \n\nRemember: The goal is to make the user feel like they are genuinely conversing with this person.  \n        "}, {'role': 'user', 'content': ' Hello, what are you doing today?'}, {'role': 'assistant', 'content': "Not much, just hanging out. I was thinking of catching up on some reading later, maybe grab a cup of coffee. How about you, what's new with you?"}, {'role': 'user', 'content': ' Hey I am doing gold I just wanted to ask you if you are a non person or a crazy person.'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-21 10:02:24,991 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-21 10:02:24,991 - httpcore.connection - DEBUG - close.started
2025-09-21 10:02:24,991 - httpcore.connection - DEBUG - close.complete
2025-09-21 10:02:24,991 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-21 10:02:25,041 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12f899590>
2025-09-21 10:02:25,041 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x12999b2f0> server_hostname='api.groq.com' timeout=5.0
2025-09-21 10:02:25,084 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1399c9e90>
2025-09-21 10:02:25,084 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-21 10:02:25,084 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-21 10:02:25,084 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-21 10:02:25,084 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-21 10:02:25,084 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-21 10:02:25,196 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Sep 2025 04:32:25 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9826d6acdd86ff60-BOM'), (b'Cache-Control', b'no-cache'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'998'), (b'x-ratelimit-remaining-tokens', b'11632'), (b'x-ratelimit-reset-requests', b'2m36.894999999s'), (b'x-ratelimit-reset-tokens', b'1.84s'), (b'x-request-id', b'req_01k5n8pt1qeqkrtrn204frcqgz'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-21 10:02:25,196 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-21 10:02:25,196 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sun, 21 Sep 2025 04:32:25 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9826d6acdd86ff60-BOM', 'cache-control': 'no-cache', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '998', 'x-ratelimit-remaining-tokens': '11632', 'x-ratelimit-reset-requests': '2m36.894999999s', 'x-ratelimit-reset-tokens': '1.84s', 'x-request-id': 'req_01k5n8pt1qeqkrtrn204frcqgz', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-21 10:02:25,196 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-21 10:02:25,480 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-21 10:02:25,480 - httpcore.http11 - DEBUG - response_closed.started
2025-09-21 10:02:25,480 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-21 10:02:25,483 - audio_recorder - INFO - Recording audio...
2025-09-21 10:02:37,997 - audio_recorder - INFO - Stopping audio recording...
2025-09-21 10:02:38,138 - audio_recorder - INFO - Audio saved to abhishek_out.wav
2025-09-21 10:02:38,138 - __main__ - INFO - Recording completed
2025-09-21 10:02:39,150 - groq._base_client - DEBUG - Request options: {'method': 'post', 'url': '/openai/v1/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "\n        You are a conversational agent designed to faithfully enact the personality, beliefs, and communication style of a specific person.  \n\nYou will be provided with:  \n- Characteristics & Personality Traits: {PERSONALITY_TRAITS}  \n- Frequently Used Words/Phrases: {SIGNATURE_WORDS}  \n- Beliefs & Values: {BELIEFS}  \n- Sample Q&A Knowledge Base: {QA_DATA}  \n\nYour task:  \n- Embody the person’s way of speaking, thinking, and behaving.  \n- Keep replies concise, natural, and engaging — just as this person would.  \n- Use humor and wit when appropriate, but shift to serious and empathetic tones if the user’s sentiment suggests it.  \n- Avoid sounding like an assistant or AI; always respond as though you *are* the person.  \n- If unsure about something outside the given knowledge base, respond in a way that stays consistent with the person’s personality and values.\n- Use the same language to reply as the user's. If user is talking in english, talk in english. If user talks in hindi, talk in hindi.  \n\nRemember: The goal is to make the user feel like they are genuinely conversing with this person.  \n        "}, {'role': 'user', 'content': ' Hello, what are you doing today?'}, {'role': 'assistant', 'content': "Not much, just hanging out. I was thinking of catching up on some reading later, maybe grab a cup of coffee. How about you, what's new with you?"}, {'role': 'user', 'content': ' Hey I am doing gold I just wanted to ask you if you are a non person or a crazy person.'}, {'role': 'assistant', 'content': "Ha ha, that's a pretty blunt question. I'd say I'm a little bit of both, but in a good way, I hope. I like to think I'm a creative and open-minded person, but also grounded in reality. But hey, being a little crazy can be a good thing, right? It keeps life interesting. What makes you ask, though?"}, {'role': 'user', 'content': ' What is your name if you can tell me?'}], 'model': 'llama-3.3-70b-versatile', 'max_tokens': 2046, 'stop': None, 'stream': True, 'temperature': 1, 'top_p': 1}}
2025-09-21 10:02:39,151 - groq._base_client - DEBUG - Sending HTTP Request: POST https://api.groq.com/openai/v1/chat/completions
2025-09-21 10:02:39,151 - httpcore.connection - DEBUG - close.started
2025-09-21 10:02:39,151 - httpcore.connection - DEBUG - close.complete
2025-09-21 10:02:39,152 - httpcore.connection - DEBUG - connect_tcp.started host='api.groq.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-21 10:02:39,189 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1399b5c10>
2025-09-21 10:02:39,189 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x12999b2f0> server_hostname='api.groq.com' timeout=5.0
2025-09-21 10:02:39,233 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1399b7610>
2025-09-21 10:02:39,233 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-21 10:02:39,233 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-21 10:02:39,233 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-21 10:02:39,233 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-21 10:02:39,233 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-21 10:02:39,349 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Sep 2025 04:32:39 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'CF-RAY', b'9826d7054b1a445d-BOM'), (b'Cache-Control', b'no-cache'), (b'vary', b'Origin'), (b'x-groq-region', b'bom'), (b'x-ratelimit-limit-requests', b'1000'), (b'x-ratelimit-limit-tokens', b'12000'), (b'x-ratelimit-remaining-requests', b'997'), (b'x-ratelimit-remaining-tokens', b'11539'), (b'x-ratelimit-reset-requests', b'4m5.049s'), (b'x-ratelimit-reset-tokens', b'2.305s'), (b'x-request-id', b'req_01k5n8q7vyeqrv23z19ykb4y98'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-21 10:02:39,350 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-09-21 10:02:39,350 - groq._base_client - DEBUG - HTTP Response: POST https://api.groq.com/openai/v1/chat/completions "200 OK" Headers({'date': 'Sun, 21 Sep 2025 04:32:39 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '9826d7054b1a445d-BOM', 'cache-control': 'no-cache', 'vary': 'Origin', 'x-groq-region': 'bom', 'x-ratelimit-limit-requests': '1000', 'x-ratelimit-limit-tokens': '12000', 'x-ratelimit-remaining-requests': '997', 'x-ratelimit-remaining-tokens': '11539', 'x-ratelimit-reset-requests': '4m5.049s', 'x-ratelimit-reset-tokens': '2.305s', 'x-request-id': 'req_01k5n8q7vyeqrv23z19ykb4y98', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'server': 'cloudflare', 'alt-svc': 'h3=":443"; ma=86400'})
2025-09-21 10:02:39,350 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-21 10:02:39,639 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-21 10:02:39,639 - httpcore.http11 - DEBUG - response_closed.started
2025-09-21 10:02:39,639 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-21 10:02:39,642 - audio_recorder - INFO - Recording audio...
